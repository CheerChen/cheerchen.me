+++
date = '2025-06-25T12:00:26+09:00'
draft = false
title = ' JINS AI：实体行业的 AI 落地 - AWS Summit Japan 2025 会议回顾'
seo_description = "深度解析 JINS 如何在 3 个月内用 3 人团队成功打造 AI 聊天导购系统，探讨 RAG 架构设计、AWS 托管服务应用，以及实体零售业 AI 落地的挑战与解决方案"
keywords = ["AI导购", "RAG", "AWS Bedrock", "零售AI", "聊天机器人", "JINS", "生成式AI", "OpenSearch"]
tags = ["AI", "AWS", "零售", "架构设计", "生成式AI", "AWS Summit Japan 2025"]
categories = ["技术分享"]
cover = '250625_pressrelease.png'
images = ['250625_pressrelease.png']
nolastmod = true
+++

## 背景

在“AWS Summit Japan 2025”的 Day1（6 月 25 日）举行的题为 **“アイウエア接客の未来を拓く～生成 AI で進化するあたらしい店舗体験への挑戦～”** 的会议上，JINS 分享了 JINS AI 的开发背景、各种巧思，以及生成式 AI 项目如何落地的一些细节。

JINS AI 是一项聊天式导购服务，顾客在店铺购买眼镜时，可以当场向生成式 AI 提问，咨询关于镜框和镜片选择的问题。

我一直认为实体行业（特别是日本）在做 AI 推进的时候往往拖泥带水，又或者没有多少运用场景。然而这个项目竟然只有三个成员，仅仅花费三个月就完成了店铺试点，这在这样的公司几乎是不可想象的。会议中提到的技术架构也有可圈可点之处，不少让我觉得 **“啊？原来不是随便做做就可以的”** 的感悟，于是简单制作了此会议记录。

## 场景聚焦

{{< figure src="1da1e727503f0d0f.jpg" >}}

这么少的人，要 3 个月内推这样一个项目落地，“1st Scope”的定义至关重要。他们说眼镜是“EC よりも実物を見て買いたい人が多い”（相比电商，更多人愿意看到实物再购买）。因此，他们没有去做一个通用的电商导购，而是把 AI 工具精准地嵌入到**镜框选择**和**镜片选择**这个决策场景中。将项目范围限定在“1st Scope”，是能在 3 个月内成功上线的关键。

## 架构设计

{{< figure src="239b048c948e9c1f.jpg" >}}

- **清晰的 RAG（检索增强生成）模式**：
    - 这套架构是典型的 RAG 模式实现。其核心流程是：
        1. 用户的请求通过负载均衡器（ELB）进入后端的 **AWS Fargate** 应用。
        2. Fargate 调用 **Amazon Bedrock**（生成式 AI 的核心）。
        3. Bedrock 并非凭空回答，而是先去 **Amazon OpenSearch Service** 中检索相关信息。
        4. OpenSearch 的数据来源是 **Amazon S3**，里面存储着简报中提到的“商品数据”和“导购知识”。右侧的注释“将 CSV 数据按行进行分块并注册”揭示了他们将知识文档切片（Chunking）后存入向量数据库的过程，这是提高 RAG 检索精度的关键一步。
    - 这个模式是当前业界应对 AI“幻觉”问题、确保回答基于事实的最佳实践。
- **明智的技术选型**：
    - **全面拥抱托管服务**：从计算（Fargate）、数据库（RDS, DynamoDB）、AI（Bedrock）到搜索（OpenSearch），几乎没有需要自己运维的服务器。这极大地释放了团队的生产力，让他们能专注于业务逻辑而非底层设施，是快速交付的核心原因。
    - **为不同目的选择不同数据库**：
        - **Amazon DynamoDB** 被用来存储“提示词、生成结果、对话历史”。这是一个绝佳的选择，因为对话日志这种非结构化、高并发写入的数据，非常适合用 NoSQL 数据库来处理。这些日志也是未来分析用户行为、迭代模型的宝贵财富。
        - **Amazon RDS** 则用于处理传统的关系型数据。
    - **安全与可扩展性**：应用被部署在**私有子网 (Private subnet)** 中，通过负载均衡器与外界通信，并且有堡垒机（Bastion）进行安全运维，这表明团队在快速开发的同时，没有牺牲安全性。使用 Fargate 和 ELB 也意味着整个系统可以根据负载自动伸缩。

## “五大障碍”

在“面向终端用户的生成式AI服务案例还很少”的情况下，JINS AI经历了反复的试错。以下列举了五个难点。

### AI 的人格设定

{{< figure src="f1a047b1a9eb6425.jpg" >}}

成功的生成式 AI 应用，是 **“品牌理念 + 用户体验设计 + 技术实现”** 三位一体的产物。在启动一个 AI 项目时，首先要问的可能不是“我们能用什么模型？”，而是“我们希望 AI 代表我们的品牌，对顾客说些什么？以何种方式说？”。这往往是很多技术主导的 AI 项目所忽略的，却是决定用户体验成败的关键。

- **以品牌为根基**：
    - 左侧的 **“Honest (诚实)”** 是 JINS 品牌的核心价值观——“对顾客诚实，走正道”。
    - 这一点至关重要，它确保了无论 AI 技术如何迭代，其与用户沟通的底层逻辑和价值观始终与品牌保持一致，避免了品牌形象的割裂。
- **将抽象理念具象化**：
    - 团队将“Honest”这个抽象概念，拆解成了五个可执行、可衡量的 AI 行为准则：
        - **彻底的诚实提案**：不为了推销而推销，真正站在用户角度提供最佳选择，这是建立信任的第一步。
        - **明确清晰的表达**：用具体、易懂的语言解释效果，避免模棱两可。
        - **分割信息以便理解**：使用标点、项目符号等方式，让信息易于阅读。这在聊天界面这种小屏幕上尤其重要，体现了优秀的用户体验设计。
        - **考虑视觉信息**：避开专业术语，使用户更容易感知优点。
        - **流畅的引导和下一步行动建议**：这是画龙点睛之笔。AI 不仅被动回答，更会主动引导，用“要不要试戴一下呢？”这样的提问推动用户的决策流程，就像一个优秀的导购员。

### 提升回答的准确性之一

{{< figure src="492836055c395619.jpg" >}}

他们没有使用单一、庞大的 AI 来处理所有问题，而是使用了 **“代理工作流 (Agentic Workflow)”** 。传统方法可能是将用户问题直接扔给一个大语言模型（LLM），但这种方法的缺点是不可靠，容易出现理解偏差。

JINS 的设计更像一个公司的专家团队（Agents）：

- **前台/总机 (前処理)**：首先对用户输入进行预处理，判断是常规问题（固定 FAQ）、违规问题，还是需要交给后台处理。这是一个高效的过滤器。
- **项目经理/调度员 (意図判断)**：这是整个流程的核心，即“判断用户意图”。正如简报所言，他们在这里使用了最强大的 AI 模型，因为它负责正确地分配任务。
- **各个领域的专家 (意図判断・RAG・AI 回答生成)**：一旦确定了用户意图（比如“想了解镜框”），任务就会被派发给专门的“镜框专家节点 (フレーム情報 RAG ノード)”。这个节点只负责处理与镜框相关的信息，同理还有“镜片专家”、“FAQ 专家”等。这大大提升了回答的专业性和准确性。

左下角明确列出了此设计的 **优点 (メリット)** 和 **课题 (課題)**。

- **优点**：能有效防止 AI 回答“跑偏”，确保回答与用户意图相关。
- **课题**：**响应速度与准确性的权衡**（步骤越多，响应越慢）；**跨节点提出建议的难度**（例如，很难同时根据镜框和镜片的信息，给出一个综合性的复杂建议）。

这个架构的另一个精妙之处在于成本和性能的优化。他们可以在最关键的“意图判断”节点上使用最先进、最昂贵的大模型，以确保方向正确；而在各个“专家节点”上，则可以使用更轻量、更便宜或经过微调的专有模型，从而在保证回答质量的同时，控制延迟和成本。

### 提升回答的准确性之二

{{< figure src="31d50c35f2df044c.jpg" >}}

- **第一步：查询改写 (Query Rewriting) - “听懂人话”**
    - 这是一个极其聪明的步骤。用户输入是口语化的、非结构化的（例如：“我是 30 多岁的女性，有黑色的圆框眼镜吗？”）。如果直接将这句话进行向量检索，效果可能并不理想。
    - JINS 的做法是，先用 Amazon Bedrock 把这句“人话”翻译成机器更容易理解的“结构化查询条件”，如右侧所示：`颜色：黑`、`品类：眼镜`、`性别：女`。这极大地提高了后续检索的精准度，确保了搜索方向从一开始就是正确的。
- **第二步：搜索范围优化 (Search Scope Optimization) - “缩小范围”**
    - 这一步是在海量商品中进行筛选。通过上一步生成的结构化条件，系统可以在向量数据库（OpenSearch）中进行元数据过滤（Metadata Filtering）。例如，它会限定只在“女士”眼镜的类别里进行搜索。
    - 这就像在图书馆找书，不是在整个图书馆里乱翻，而是先确定要去“文学区”，再在书架上寻找。这不仅提升了准确性，也提高了检索效率。
- **第三步：重排序 (Reranking) - “精挑细选”**
    - 这是提升最终结果质量的点睛之笔。向量检索（RAG）可能会初步找出 15 个相关的结果，但它们之间的相关性排序可能并不完美。
    - JINS 再次利用了 Bedrock 的强大语言理解能力，对这 15 个初步结果进行“二次审核”，根据原始问题的语境进行重新排序，挑出最最相关的 Top 3。LLM 在语境理解上的细微差别判断能力，通常优于单纯的向量相似度计算。

### 提升回答的准确性之三

- **引入 Langfuse 实现可观测性**
- **会话历史（内存）管理**
    - 在工作流中产生的即时数据（如用户意图、RAG 检索结果）被保存在内存中 (on-memory)，对话结束即清除。
    - 为了复盘和分析。JINS 将过去所有的对话历史都存储在 PostgreSQL 数据库中。

### 安全与合规之一

{{< figure src="a26d886373f04de0.jpg" >}}

- **问题的核心：解锁数据价值，同时保护隐私**
    - 任何一个 AI 应用，其能力都取决于其学习的数据。最有价值的数据，莫过于真实的用户交互数据（例如导购和顾客的对话记录）。但这些数据里充满了个人隐私信息（姓名、电话、地址等）。
    - JINS 面临的挑战是：如何在不侵犯用户隐私的前提下，利用这些宝贵数据来优化 AI？这个数据清洗和脱敏（Masking）流程就是他们的答案。
- **一个设计精良的自动化与人工协同流程**：
    - 这个流程设计得非常严谨，可以概括为 **“两轮 AI 处理 + 双重人工审核”**，堪称典范：
        - **第①、②步（自动化初审）**：文件上传到 S3 后，自动触发 Lambda 函数。它会先用正则表达式做一些基础清洗，然后调用 Bedrock 进行第一轮 AI 智能脱敏。这能高效地处理掉 80%-90% 的常规隐私数据。
        - **第③步（人工复核 + AI 精加工）**：这是关键的“人机协作”环节。**人**来检查第一轮 AI 脱敏的结果，对于 AI 可能遗漏或处理不当的地方，可以触发**第二次**更精细的 LLM 脱敏处理。机器负责效率，人负责把关和处理疑难杂症。
        - **第④步（最终审核与入库）**：在数据最终被注册到 OpenSearch 知识库之前，还有一次**人工的最终确认**。这个“双重确认”机制，最大限度地保证了进入 RAG 系统的数据是“干净”且安全的。

### 安全与合规之二

{{< figure src="837eee11a0b6fcfb.jpg" >}}

- **从风险识别到用户协议的清晰逻辑**：
    - 这张图的逻辑非常清晰，从左到右层层递进：
        - **识别核心风险 (懸念事項)**：首先，诚实地列出两个最大的风险：① AI 可能输出不当内容（声誉风险）；② AI 可能获取到个人信息（隐私风险）。
        - **制定内部对策 (対応方針)**：针对风险，制定内部的应对策略。这不仅包括技术控制，更重要的是确立了原则，例如“个人信息绝不用于 AI 学习”、“建立用户反馈机制”等。
        - **落地为用户协议 (利用規約作成)**：最后，将这些内部原则，提炼成用户必须同意的、清晰的条款。
- **简洁有效的用户协议**：
    - 他们没有搞一个冗长复杂的法律文件，而是提炼出了三个核心要点，让用户一目了然：
        - **✓ 这是 Beta 版**：主动管理用户期望，告知用户产品可能不完美，为潜在的错误提供了“免责声明”。
        - **✓ 请勿恶意使用**：为平台提供了封禁恶意用户的正当理由。
        - **✓ 请勿输入个人信息**：将保护隐私的责任与用户共担，既是提醒也是法律依据。
    - 这种做法远比让用户在一个几十页的协议上打勾要有效得多，体现了对用户知情权的尊重。
- **全球化视野**：
    - 右下角一个非常重要的细节是 **“※日英中で対応” (支持日文、英文、中文)**。这表明团队在项目初期就考虑到了国际化的需求，为不同语言的用户提供了相同的规则和保障，体现了其作为全球品牌的严谨性。

### “最后一公里”

{{< figure src="10c2af91308c5552.jpg" >}}

1. **措施 1：场景化的工具设计 (在对的时间，说对的话)**
    - 他们没有简单地展示一个二维码，而是通过指示牌（サイネージ）创造了一个明确的使用场景：“当您身边**暂时没有店员**时，请随时与我商量”。
    - 这句话非常巧妙，它瞬间打消了用户的两种疑虑：① “我该什么时候用？”（答案：店员忙的时候）；② “用这个 AI 会不会很奇怪？”（答案：不会，这是被鼓励的）。它将 AI 定位成一个贴心的“B 方案”，而非一个令人困惑的新工具。

2. **措施 2：店员主动引导 (人机协同的最佳实践)**
    - 这是整个引导策略中最智慧的一环。他们将店员的角色从“可能被 AI 取代的人”转变成了“AI 的大使和引导者”。
    - 尤其关键的是那句前提：**“不强制推荐 AI”**。当有空时，店员依然提供传统服务。这表明 AI 是来**分担压力、提升效率**的辅助工具，而不是来抢饭碗的。这不仅让顾客感到被尊重，也极大地促进了内部员工对新工具的接纳和支持。店员可以在高峰期，主动引导顾客（特别是外国游客）使用 AI，实现人力的最佳调配。

3. **措施 3：店内多点部署 (无缝融入购物路径)**
    - 针对那些“就想自己逛逛”的顾客，他们在店内各个关键位置（入口、货架、展台）都设置了引导工具。
    - 这使得 AI 工具无缝地融入了顾客的自然购物路径中。无论顾客逛到哪里，当他产生疑问时，JINS AI 的入口就在他身边，真正做到了“在需要时，随时可用”。

## 落地效果如何

{{< figure src="6133999bb37abfcf.jpg" >}}

就这样，JINS AI 的 Beta 版完成了，并从 2025 年 4 月起开始了为期约 3 个月的试点。在实际店铺中，该服务尤其受到外国游客的好评，也满足了那些“想问店员问题，但最终还是想自己决定”的顾客需求。

最令人担心的“是否会被用于意料之外的用途”这一点，实际情况是绝大多数问题都是为了辅助购买，其中近两成的对话最终进入了选择眼镜或显示眼镜摘要画面的阶段，这表明对话正朝着购买方向发展。从内容上看，问题也如预期那样，主要围绕解决购买眼镜的“三大困惑”，一种“由生成式 AI 替代店员”的全新顾客体验正在逐步形成。

## 提问环节

整理完资料我把三个问题丢给 Gemini。

>1. Agentic Workflow 是不是一种在弱 LLM 模型下的设计？如果在更优秀的 LLM 下是不是就可以不需要这个架构了？

{{< gemini >}}

这是一个非常棒的问题，触及了 AI 应用架构的未来方向。

**简短的回答是：不，即使在更强大的 LLM 下，Agentic Workflow（代理工作流）这种架构思想不仅不会消失，反而会变得更加重要和普遍。**

它并非是为了弥补“弱 LLM”而存在的，而是为了构建**可靠、可控、可扩展**的复杂 AI 系统。

我们可以这样理解：

1. **分工与协作的必然性 (Divide and Conquer)**：
    - 想象一下，即使你有一个全知全能的“超级 CEO”（未来的强 LLM），你依然需要一个公司架构，需要财务部、法务部、市场部等各个“专家部门”（即不同的 Agent 节点）。
    - CEO 的工作是理解总体目标，然后将任务**调度**给最合适的专家去执行。Agentic Workflow 就是这个“公司架构”。它让 LLM 扮演“调度员”的角色，去调用各种“专家工具”（如 RAG 检索、数据库查询、图像生成等）。

2. **确定性与可靠性**：
    - 单一的、巨大的 LLM 调用，其行为有时像一个“黑箱”，输出的结果可能有一定的随机性。对于严肃的商业应用来说，这是不可接受的。
    - 而 Agentic Workflow 将一个复杂的任务拆解成多个简单的、定义明确的步骤。**每一步都更可控、更可预测**。如果出错了，我们能非常清楚地知道是哪一个“节点”（例如“镜框信息 RAG 节点”）出了问题，便于调试和优化。

3. **成本与效率的优化**：
    - 这在 JINS 的案例中体现得淋漓尽致。即使未来有一个思考能力极强的 LLM-X，它的调用成本可能依然非常高昂。
    - Agentic Workflow 允许我们进行**智能的成本优化**：在最关键的“意图判断”环节，我们使用昂贵的“思考型”LLM-X；而在后续的“格式化输出”、“简单问答”等环节，我们可以调用更便宜、更快速的轻量级模型。这样可以在保证效果的同时，极大地降低成本和延迟。

{{< /gemini >}}

>2. “AI 应用，其能力都取决于其学习的数据”如何理解？LLM 模型参数已定型，这个（已打码）数据如何能优化应用表现？

{{< gemini >}}

您这个问题是一个普遍的误区（哇靠，我被他鄙视了）。这里的“学习的数据”需要区分为两种：

1. **LLM 的“预训练数据” (Pre-training Data)**：

    - 这是指像 GPT-4、Claude、Gemini 等基础大模型在诞生之前，学习的来自互联网、书籍等的**海量通用知识**。
    - 这部分学习决定了模型的“智力基础”和“世界观”，其参数在训练完成后确实是**定型**的。您说的“模型参数已定型”指的就是这个。JINS 团队不会去修改这部分。

2. **RAG 应用的“检索数据” (Retrieval Data)**：

    - JINS AI 这个应用的表现，主要不依赖于修改模型参数，而是依赖于**在用户提问的瞬间，能够提供给 LLM 的、高质量的“参考资料”**。
    - 这就是 RAG（检索增强生成）的核心。可以把它想象成一个**“开卷考试”**：
        - **LLM**：是一个非常聪明的“学生”，但它不知道 JINS 内部的、最新的、私有的信息（比如某款眼镜的具体库存、针对“高度近视”的内部销售技巧等）。
        - **RAG 知识库（OpenSearch 里的数据）**：就是发给这位学生的“教科书”或“小抄”。
    - JINS AI 的表现好坏，直接取决于这本“教科书”的质量。

**那么，已打码的数据如何优化表现？**

这正是 JINS 数据处理流程的精妙之处。他们打码（脱敏）的是**个人身份信息（PII）**，如姓名、电话等，但保留了最有价值的**业务交互模式 (Business Interaction Patterns)**。

例如，一条原始对话记录是：

> “_黑尾玲奈女士 _ 您好，我脸比较 _ 圆_，想要一副适合 _ 远程办公 _ 的 _ 黑色 _ 眼镜，预算 _1 万日元 _，有什么推荐吗？”

脱敏后存入 RAG 知识库的数据可能是：

> **问题模板**：“[女性] 顾客，脸型 [圆形]，使用场景 [远程办公]，颜色偏好 [黑色]，预算 [中等]，请求镜框推荐。” **解决方案**：“推荐了 [产品型号 A]、[产品型号 B]。特点是轻量、设计上可以修饰脸型。顾客反馈良好。”

当新的用户提出类似问题时，AI 就能从知识库中检索到这个高质量的“问答对”，即使不知道顾客姓名，也能给出非常精准的推荐。因此，**持续地将这些已打码的、高质量的真实交互案例加入 RAG 知识库，就是在不断地更新和优化那本“教科书”，从而让“学生”（LLM）的“开卷考试”成绩越来越好。**

{{< /gemini >}}

>3. 什么叫做“为了 PoC 而做 PoC”？

{{< gemini >}}

“为了 PoC 而做 PoC”是一个在企业创新中非常常见的“陷阱”，也被称为“PoC 炼狱” (PoC Purgatory) 或“创新剧场” (Innovation Theater)。

首先，**PoC (Proof of Concept)** 的本意是“概念验证”，即通过一个最小化的、快速的实验，来验证一个想法在技术上是否可行、在商业上是否有潜在价值。

**一个健康的、战略性的 PoC (JINS 的做法)**：

- **目的**：为了回答一个具体的商业问题（例如：“AI 能否有效解决顾客选镜的困惑？”）。
- **目标**：验证完毕后，如果成功，就进入下一阶段（试点、推广）；如果失败，就从中学到经验教训，快速调整方向。
- **终点**：一个能够落地的、创造价值的真实产品。

**一个“为了 PoC 而做 PoC”的项目**：

- **目的**：往往是为了响应“高层号召”或追逐技术热点（“我们公司也必须有生成式 AI！”）。
- **目标**：PoC 本身就是目标。只要能做出一个看起来很酷的 Demo，可以在大会上展示、可以在 PPT 里汇报，项目就“成功”了。
- **终点**：汇报演示结束，项目也就结束了。它从未考虑过如何与现有业务结合、如何解决安全合规问题、如何处理真实数据、如何推广给用户等。它只是一个漂浮在空中的、与现实脱节的“技术烟花”。

{{< /gemini >}}
